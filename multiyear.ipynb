{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which statistical category (rushing/passing/receiving/interceptions/sacks/tackles/Field_Goals/Punting:rushing\n",
      "What type of season (pre, reg, post): reg\n",
      "Starting Year: 2019\n",
      "Last Year: 2019\n"
     ]
    }
   ],
   "source": [
    "#rushing/passing/receiving/interceptions/sacks(e.1982)/tackles(e.2001)/Field_Goals/Punting(e.1939)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "statisticCategory = input(\"Which statistical category (rushing/passing/receiving/interceptions/sacks/tackles/Field_Goals/Punting:\")\n",
    "if (statisticCategory.upper() != \"SACKS\") & (statisticCategory.upper() != \"RUSHING\") & (statisticCategory.upper() != \"PASSING\") & (statisticCategory.upper() != \"RECEIVING\") & (statisticCategory.upper() != \"INTERCEPTIONS\") & (statisticCategory.upper() != \"TACKLES\") & (statisticCategory.upper() != \"FIELD_GOALS\") & (statisticCategory.upper() != \"PUNTING\"):\n",
    "    raise Exception(\"ERROR: statistical category must be one of the listed\")\n",
    "\n",
    "\n",
    "season_type = input(\"What type of season (pre, reg, post): \")\n",
    "if (season_type.upper() != 'PRE') & (season_type.upper() != 'REG') & (season_type.upper() != \"POST\") :\n",
    "    raise Exception(\"ERROR: Season Type needs to be either pre, reg, or post\")\n",
    "        \n",
    "start_season = input(\"Starting Year: \")\n",
    "if (statisticCategory.upper() == \"SACKS\") & (int(start_season) < 1982):\n",
    "    raise Exception(\"ERROR: For sacks, the starting year can't be less than 1932\")\n",
    "if (statisticCategory.upper() == \"TACKLES\") & (int(start_season) < 2001):\n",
    "    raise Exception(\"ERROR: For tackles, the starting year can't be less than 2001\")\n",
    "if (statisticCategory.upper() == \"PUNTING\") & (int(start_season) < 1939):\n",
    "    raise Exception(\"ERROR: For punting, the starting year can't be less than 1939\")\n",
    "if (int(start_season) < 1932) | int(start_season) > now.year :\n",
    "    raise Exception(\"ERROR: The starting year can't be less than 1932\")\n",
    "    \n",
    "last_season = input(\"Last Year: \")\n",
    "if (int(last_season) < 1932) | int(last_season) > now.year:\n",
    "    raise Exception(\"ERROR: The last year can't be less than 1932 and more than the current year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    }
   ],
   "source": [
    "for year in range(int(start_season), int(last_season) + 1):\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for season in range(int(start_season), int(last_season) + 1):\n",
    "    p = 1\n",
    "    payload = {\"statisticCategory\":statisticCategory.upper(),\"seasonType\":season_type.upper(),\"d-447263-p\":str(p),\"season\":season}\n",
    "    url = 'http://www.nfl.com/stats/categorystats'\n",
    "    response = requests.get(url,params=payload)\n",
    "    time.sleep(1)\n",
    "    print(\"Response:\", response.status_code,response.url) #200 means it went through\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    #The website table is partitioned into multiple pages.  We need to know how many pages to iterate\n",
    "\n",
    "    pagingText = soup.find(\"span\", {\"class\": \"linkNavigation floatRight\"})\n",
    "    print(pagingText == None)\n",
    "    if(pagingText == None):\n",
    "        pagingLinks = 0\n",
    "        pages = 0\n",
    "        print(\"Number of page links:\",0)\n",
    "        columnHeader = []\n",
    "        header = soup.find('table', attrs={'id':'result'}).find_all('th')\n",
    "        for c in header:\n",
    "            columnHeader.append(c.text)\n",
    "        columnHeader = [c.strip('\\n') for c in columnHeader]\n",
    "        if (statisticCategory.upper() == \"TACKLES\") | (statisticCategory.upper() == \"SACKS\") | (statisticCategory.upper() == \"INTERCEPTIONS\"):\n",
    "            columnHeader = columnHeader[4:]\n",
    "        print(columnHeader)\n",
    "\n",
    "        tableRows = []\n",
    "\n",
    "        for pg in range(1,2):\n",
    "\n",
    "            #pause our code for a second so that we are not spamming the website with requests. This helps us avoid getting flagged as a spammer.\n",
    "            time.sleep(5)\n",
    "\n",
    "            #update page number in payload\n",
    "            payload[\"d-447263-p\"] = pg\n",
    "            response = requests.get(url,params=payload)\n",
    "            print(\"Page:\",pg,\"url:\",response.url)\n",
    "            soup = BeautifulSoup(response.text,'html.parser')\n",
    "            table = soup.find('table', attrs={'id':'result'})\n",
    "            rows = table.find_all('tr')\n",
    "\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                if cols:\n",
    "                    cols = [ele.text.strip() for ele in cols]\n",
    "                    tableRows.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "\n",
    "    else:\n",
    "        pagingLinks = pagingText.findAll(\"a\")\n",
    "        pages = len(pagingLinks)\n",
    "        print(\"Number of page links:\",len(pagingLinks))\n",
    "        columnHeader = []\n",
    "        header = soup.find('table', attrs={'id':'result'}).find_all('th')\n",
    "        for c in header:\n",
    "            columnHeader.append(c.text)\n",
    "        columnHeader = [c.strip('\\n') for c in columnHeader]\n",
    "        if (statisticCategory.upper() == \"TACKLES\") | (statisticCategory.upper() == \"SACKS\") | (statisticCategory.upper() == \"INTERCEPTIONS\"):\n",
    "            columnHeader = columnHeader[4:]\n",
    "        print(columnHeader)\n",
    "\n",
    "        tableRows = []\n",
    "\n",
    "        for pg in range(1,pages+1):\n",
    "\n",
    "            #pause our code for a second so that we are not spamming the website with requests. This helps us avoid getting flagged as a spammer.\n",
    "            time.sleep(5)\n",
    "\n",
    "            #update page number in payload\n",
    "            payload[\"d-447263-p\"] = pg\n",
    "            response = requests.get(url,params=payload)\n",
    "            print(\"Page:\",pg,\"url:\",response.url)\n",
    "            soup = BeautifulSoup(response.text,'html.parser')\n",
    "            table = soup.find('table', attrs={'id':'result'})\n",
    "            rows = table.find_all('tr')\n",
    "\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                if cols:\n",
    "                    cols = [ele.text.strip() for ele in cols]\n",
    "                    tableRows.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "\n",
    "    resultsDF = pd.DataFrame(tableRows, columns=columnHeader)\n",
    "    resultsDF['Season'] = season\n",
    "    display(resultsDF.head(1),resultsDF.shape)\n",
    "    x.append(resultsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]\n",
    "x[0].append(x[1:len(x)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = x[0].append(x[1:len(x)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseFileName = \"NFL_Stats_Demo_\"\n",
    "\n",
    "results.to_excel(baseFileName + statisticCategory + \"_\" + season_type + \"_\" + start_season + \"_\" + last_season + \".xlsx\",index=False)\n",
    "results.to_csv(baseFileName + statisticCategory + \"_\" + season_type + \"_\" + start_season + \"_\" + last_season + \".csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
